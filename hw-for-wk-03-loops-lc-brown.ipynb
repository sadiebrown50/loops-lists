{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz4lidEcC-wu"
   },
   "source": [
    "# Homework for Week 3\n",
    "\n",
    "The goal for this homework is to see the relevant journalistic uses for what we learned in class in week 4.\n",
    "\n",
    "1. Using the power of automation for iterate through tedious, but important tasks.\n",
    "2. Tapping Python to iterate through calculations. In a few weeks, you'll be doing this on millions of rows.\n",
    "3. Allowing us to slow down how fast our code runs to avoid detection or being blocked when we start scraping websites!\n",
    "4. Processing data we have scraped into dataframes and/or csv files for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Counter\n",
    "* Build a counter that counts from 2 to 10, but only even numbers.\n",
    "* Print the counter numbers in statement that reads: \"The even number is [whatever the even number is]\".\n",
    "* Once it reaches 10, it should print \"Done counting from 2 to 10 even numbers!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The even number is 2\n",
      "The even number is 4\n",
      "The even number is 6\n",
      "The even number is 8\n",
      "The even number is 10\n",
      "Done counting from 2 to 10 even numbers!\n"
     ]
    }
   ],
   "source": [
    "## build here:\n",
    "counter = 0\n",
    "while counter < 10:\n",
    "    counter += 2\n",
    "    print(f\"The even number is {counter}\")\n",
    "\n",
    "\n",
    "print(\"Done counting from 2 to 10 even numbers!\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (519464492.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/pk/h683hh6n623c29s3jld048240000gn/T/ipykernel_41928/519464492.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    * Add a timer to the previous code so it runs every 3 to 15 seconds\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## 2. Build a counter with a timer\n",
    "* Add a timer to the previous code so it runs every 3 to 15 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build here:\n",
    "import datetime as dt\n",
    "import time\n",
    "from random import randint\n",
    "counter = 2\n",
    "while counter < 12:\n",
    "    current_time = dt.datetime.now()\n",
    "    snoozer = randint(3, 15)\n",
    "    print(f\"The count is {counter} at exactly {current_time}\")\n",
    "    \n",
    "    time.sleep(snoozer)\n",
    "    counter += 2\n",
    "\n",
    "\n",
    "print(\"Done counting from 2 to 10 even numbers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEXSVGi2C-w4"
   },
   "source": [
    "## 3.  Combine different data points together \n",
    "\n",
    "#### You scrape some URLs and place them in a list called myURLS (provided below):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQwOrDIWC-w4"
   },
   "outputs": [],
   "source": [
    "## run this cell to activate the list\n",
    "myURLS = [\n",
    "    'great-unique-data-1.html',\n",
    "    'great-unique-data-2.html',\n",
    "    'great-unique-data-3.html',\n",
    "    'great-unique-data-4.html',\n",
    "    'great-unique-data-5.html',\n",
    "    'great-unique-data-6.html',\n",
    "    'great-unique-data-7.html',\n",
    "    'great-unique-data-8.html',\n",
    "    'great-unique-data-9.html',\n",
    "    'great-unique-data-10.html',\n",
    "    'great-unique-data-11.html',\n",
    "    'great-unique-data-12.html',\n",
    "    'great-unique-data-13.html',\n",
    "    'great-unique-data-14.html',\n",
    "    'great-unique-data-15.html'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGrsmmioC-w4",
    "outputId": "daf42c56-696e-45c5-daec-967ea4801db2"
   },
   "outputs": [],
   "source": [
    "## CALL myURLS to check it out\n",
    "myURLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W4WZ9-_C-w5"
   },
   "source": [
    "### * You realize that these URLs are missing the base of \"http://www.importantsite.com/\"\n",
    "### * Use a ```for loop``` to join the base URL to every partial URL in your list.\n",
    "### * Print each FULL URL\n",
    "It should look like: ```\"http://www.importantsite.com/great-unique-data-14.html``` but with unique numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFqX3JypC-w5",
    "outputId": "7322e6a3-c720-455b-e9fe-965e185f51bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.importantsite.com/great-unique-data-1.html\n",
      "http://www.importantsite.com/great-unique-data-2.html\n",
      "http://www.importantsite.com/great-unique-data-3.html\n",
      "http://www.importantsite.com/great-unique-data-4.html\n",
      "http://www.importantsite.com/great-unique-data-5.html\n",
      "http://www.importantsite.com/great-unique-data-6.html\n",
      "http://www.importantsite.com/great-unique-data-7.html\n",
      "http://www.importantsite.com/great-unique-data-8.html\n",
      "http://www.importantsite.com/great-unique-data-9.html\n",
      "http://www.importantsite.com/great-unique-data-10.html\n",
      "http://www.importantsite.com/great-unique-data-11.html\n",
      "http://www.importantsite.com/great-unique-data-12.html\n",
      "http://www.importantsite.com/great-unique-data-13.html\n",
      "http://www.importantsite.com/great-unique-data-14.html\n",
      "http://www.importantsite.com/great-unique-data-15.html\n"
     ]
    }
   ],
   "source": [
    "## build here:\n",
    "baseURL = \"http://www.importantsite.com/\"\n",
    "for URL in myURLS:\n",
    "    full_URL = baseURL + URL\n",
    "    print (full_URL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-DNZj4OC-w5",
    "outputId": "d6a7b497-56fb-47bd-aed1-4f9cd19ae2a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great-unique-data-1.html',\n",
       " 'great-unique-data-2.html',\n",
       " 'great-unique-data-3.html',\n",
       " 'great-unique-data-4.html',\n",
       " 'great-unique-data-5.html',\n",
       " 'great-unique-data-6.html',\n",
       " 'great-unique-data-7.html',\n",
       " 'great-unique-data-8.html',\n",
       " 'great-unique-data-9.html',\n",
       " 'great-unique-data-10.html',\n",
       " 'great-unique-data-11.html',\n",
       " 'great-unique-data-12.html',\n",
       " 'great-unique-data-13.html',\n",
       " 'great-unique-data-14.html',\n",
       " 'great-unique-data-15.html']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## call myURLS.\n",
    "## do they have the full url?\n",
    "myURLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM6-d1hXC-w5"
   },
   "source": [
    "## 4. Update myURLS and store full URLS in a new list\n",
    "\n",
    "#### * Instead of just printing the joined URLs, create a new list called ```full_URLS`` that holds the full URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vggh0aYAC-w5",
    "outputId": "7e1f46d1-0b1c-4784-c838-798bea161370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.importantsite.com/great-unique-data-1.html',\n",
       " 'http://www.importantsite.com/great-unique-data-2.html',\n",
       " 'http://www.importantsite.com/great-unique-data-3.html',\n",
       " 'http://www.importantsite.com/great-unique-data-4.html',\n",
       " 'http://www.importantsite.com/great-unique-data-5.html',\n",
       " 'http://www.importantsite.com/great-unique-data-6.html',\n",
       " 'http://www.importantsite.com/great-unique-data-7.html',\n",
       " 'http://www.importantsite.com/great-unique-data-8.html',\n",
       " 'http://www.importantsite.com/great-unique-data-9.html',\n",
       " 'http://www.importantsite.com/great-unique-data-10.html',\n",
       " 'http://www.importantsite.com/great-unique-data-11.html',\n",
       " 'http://www.importantsite.com/great-unique-data-12.html',\n",
       " 'http://www.importantsite.com/great-unique-data-13.html',\n",
       " 'http://www.importantsite.com/great-unique-data-14.html',\n",
       " 'http://www.importantsite.com/great-unique-data-15.html']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build here:\n",
    "Full_URLS = []\n",
    "\n",
    "for URL in myURLS:\n",
    "    joined_URLS = baseURL + URL\n",
    "    Full_URLS.append(joined_URLS)\n",
    "    \n",
    "Full_URLS\n",
    "\n",
    "##I remember this from last semester!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. You have a long list of toxins. Run the next cell to pull the list into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxins = [\n",
    "        \"Recombinant Bovine Growth Hormone\", \n",
    "        \"Butylated Hydroxyanisole\", \n",
    "        \"Sodium Aluminum Sulphate\",\n",
    "        \"Potassium Aluminum Sulphate\",\n",
    "        \"Sodium Nitrite\",\n",
    "        \"Polycyclic Aromatic Hydrocarbons\",\n",
    "        \"Dioxins\",\n",
    "        \"Heterocyclic Amines\",\n",
    "        \"Butylated Hydroxytoluene\",\n",
    "        \"Polyvinyl Chloride\",\n",
    "        \"PVC\",\n",
    "        \"Perfluorooctanoic Acid\",\n",
    "        \"PFOA\",\n",
    "        \"Triclosan\",\n",
    "        \"Bisphenol-A\",\n",
    "        \"BPA\",\n",
    "        \"Formaldehyde\",\n",
    "        \"Naphthalene\",\n",
    "        \"Asbestos\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You realize that the toxins from \"Polyvinyl Chloride\" to the end of the list are hormone disruptors.\n",
    "\n",
    "Programmatically create a new list using List Comprehension called ```hormone_inhibitors``` that includes all the chemicals from \"Polyvinyl Chloride\" to \"Asbestos\".\n",
    "\n",
    "- Do NOT manually count to figure out the index position of \"Polyvinyl Chloride\".\n",
    "- Do NOT manually type out a new list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### answer here (create more cells if necessary)\n",
    "## we can figure out the position for \"Polyvinyl Chloride\"\n",
    "toxins.index(\"Polyvinyl Chloride\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in one line we can call the index position all the way to the end.\n",
    "hormone_inhibitors = [toxin for toxin in toxins if toxins.index(toxin) > 8 ]\n",
    "\n",
    "##This one was a little tricky, but I got it surprisingly quick!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Polyvinyl Chloride',\n",
       " 'PVC',\n",
       " 'Perfluorooctanoic Acid',\n",
       " 'PFOA',\n",
       " 'Triclosan',\n",
       " 'Bisphenol-A',\n",
       " 'BPA',\n",
       " 'Formaldehyde',\n",
       " 'Naphthalene',\n",
       " 'Asbestos']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hormone_inhibitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using a ```for loop``` create a list called ```sodium_fl``` that captures only the toxins that have the word ```sodium``` in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build it here\n",
    "sodium_fl = []\n",
    "substring = \"Sodium\"\n",
    "for toxin in toxins:\n",
    "    if substring in toxin:\n",
    "        sodium_fl.append(toxin)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sodium Aluminum Sulphate', 'Sodium Nitrite']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sodium_fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using a ```list comprehension``` create a list called ```sodium_lc``` that captures only the toxins that have the word ```sodium``` in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_IubbqlC-w4",
    "outputId": "b680eae8-4ed3-4e0f-bf4b-f96ca0a17f46"
   },
   "outputs": [],
   "source": [
    "## build here: \n",
    "\n",
    "sodium_lc = [toxin for toxin in toxins if substring in toxin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sodium Aluminum Sulphate', 'Sodium Nitrite']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sodium_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ```for loop``` Calculations\n",
    "\n",
    "Run the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this cell\n",
    "monthly_rent_2022 = [3500, 2700, 1200, 5000, 3500, 2000, 4300, 3400, 3900 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this fast gentrifying neighborhood, the monthly rent will increase by 27.8 percent for 2023.  Using a ```for loop``` create a new list called ```monthly_rent_2023_fl``` that shows the increased rent rounded to ZERO decimal places. \n",
    "\n",
    "Do the calculation programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### answer here (create more cells if necessary)\n",
    "monthly_rent_2023_fl = []\n",
    "\n",
    "for rent in monthly_rent_2022:\n",
    "    increased_rent = round(rent * 1.278)\n",
    "    monthly_rent_2023_fl.append(increased_rent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4473, 3451, 1534, 6390, 4473, 2556, 5495, 4345, 4984]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_rent_2023_fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ```list comprehension``` Calculation\n",
    "\n",
    "The same scenario as above but now create a list called ```monthly_rent_2023_lc``` using ```list comprehension```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "### answer here (create more cells if necessary)\n",
    "monthly_rent_2023_lc = [round(rent * 1.278) for rent in monthly_rent_2022]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4473, 3451, 1534, 6390, 4473, 2556, 5495, 4345, 4984]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_rent_2023_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ```zip``` it\n",
    "\n",
    "You scrape a website and end up with the lists below.\n",
    "\n",
    "Use both the methods we covered in class to create a ```df``` and then a ```csv``` file from these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The content you scraped is now in the following lists:\n",
    "\n",
    "source_files = ['7681804Q.pdf', '7543447R.pdf', '7864672J.pdf', '8073426Q.pdf', '7909756P.pdf', '7749758M.pdf', '7917101M.pdf', '7880385Y.pdf', '7958281Z.pdf', '7836909K.pdf', '7891371L.pdf', '7096205N.pdf']\n",
    "\n",
    "date_appeals = ['10-Jan-18', '31-May-17', '20-Nov-18', '6-Dec-19', '12-Feb-19', '1-May-18', '25-Feb-19', '18-Dec-18', '8-May-19', '2-Oct-18', '8-Jan-19', '6-Aug-15']\n",
    "\n",
    "cognition_related = [False, True, False, False, True, False, False, True, True, True, False, False]\n",
    "\n",
    "positive_decisions = [False, True, True, False, False, True, True, True, True, True, False, True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A- Use the zip() into list of dictionaries method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here – create more cells as necessary\n",
    "method_1 = []\n",
    "\n",
    "for (file, date, cognition, decision)\\\n",
    "in zip (source_files, date_appeals, cognition_related, positive_decisions):\n",
    "    method_1.append({\n",
    "        \"source_files\": file,\n",
    "        \"date_appeal\": date,\n",
    "        \"cognition_related\": cognition,\n",
    "        \"positive_decision\" : decision\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_files': '7681804Q.pdf',\n",
       "  'date_appeal': '10-Jan-18',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': False},\n",
       " {'source_files': '7543447R.pdf',\n",
       "  'date_appeal': '31-May-17',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True},\n",
       " {'source_files': '7864672J.pdf',\n",
       "  'date_appeal': '20-Nov-18',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True},\n",
       " {'source_files': '8073426Q.pdf',\n",
       "  'date_appeal': '6-Dec-19',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': False},\n",
       " {'source_files': '7909756P.pdf',\n",
       "  'date_appeal': '12-Feb-19',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': False},\n",
       " {'source_files': '7749758M.pdf',\n",
       "  'date_appeal': '1-May-18',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True},\n",
       " {'source_files': '7917101M.pdf',\n",
       "  'date_appeal': '25-Feb-19',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True},\n",
       " {'source_files': '7880385Y.pdf',\n",
       "  'date_appeal': '18-Dec-18',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True},\n",
       " {'source_files': '7958281Z.pdf',\n",
       "  'date_appeal': '8-May-19',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True},\n",
       " {'source_files': '7836909K.pdf',\n",
       "  'date_appeal': '2-Oct-18',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True},\n",
       " {'source_files': '7891371L.pdf',\n",
       "  'date_appeal': '8-Jan-19',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': False},\n",
       " {'source_files': '7096205N.pdf',\n",
       "  'date_appeal': '6-Aug-15',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_files</th>\n",
       "      <th>date_appeal</th>\n",
       "      <th>cognition_related</th>\n",
       "      <th>positive_decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7681804Q.pdf</td>\n",
       "      <td>10-Jan-18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7543447R.pdf</td>\n",
       "      <td>31-May-17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7864672J.pdf</td>\n",
       "      <td>20-Nov-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8073426Q.pdf</td>\n",
       "      <td>6-Dec-19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7909756P.pdf</td>\n",
       "      <td>12-Feb-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7749758M.pdf</td>\n",
       "      <td>1-May-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7917101M.pdf</td>\n",
       "      <td>25-Feb-19</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7880385Y.pdf</td>\n",
       "      <td>18-Dec-18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7958281Z.pdf</td>\n",
       "      <td>8-May-19</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7836909K.pdf</td>\n",
       "      <td>2-Oct-18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7891371L.pdf</td>\n",
       "      <td>8-Jan-19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7096205N.pdf</td>\n",
       "      <td>6-Aug-15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source_files date_appeal  cognition_related  positive_decision\n",
       "0   7681804Q.pdf   10-Jan-18              False              False\n",
       "1   7543447R.pdf   31-May-17               True               True\n",
       "2   7864672J.pdf   20-Nov-18              False               True\n",
       "3   8073426Q.pdf    6-Dec-19              False              False\n",
       "4   7909756P.pdf   12-Feb-19               True              False\n",
       "5   7749758M.pdf    1-May-18              False               True\n",
       "6   7917101M.pdf   25-Feb-19              False               True\n",
       "7   7880385Y.pdf   18-Dec-18               True               True\n",
       "8   7958281Z.pdf    8-May-19               True               True\n",
       "9   7836909K.pdf    2-Oct-18               True               True\n",
       "10  7891371L.pdf    8-Jan-19              False              False\n",
       "11  7096205N.pdf    6-Aug-15              False               True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(method_1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"method_1.csv\", encoding = \"UTF-8\", index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- Use the zip() into list of tuples method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here – create more cells as necessary\n",
    "\n",
    "## still don't think I fully understand this\n",
    "method_2 = []\n",
    "for x\\\n",
    "in zip (source_files, date_appeals, cognition_related, positive_decisions):\n",
    "  method_2.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7681804Q.pdf', '10-Jan-18', False, False),\n",
       " ('7543447R.pdf', '31-May-17', True, True),\n",
       " ('7864672J.pdf', '20-Nov-18', False, True),\n",
       " ('8073426Q.pdf', '6-Dec-19', False, False),\n",
       " ('7909756P.pdf', '12-Feb-19', True, False),\n",
       " ('7749758M.pdf', '1-May-18', False, True),\n",
       " ('7917101M.pdf', '25-Feb-19', False, True),\n",
       " ('7880385Y.pdf', '18-Dec-18', True, True),\n",
       " ('7958281Z.pdf', '8-May-19', True, True),\n",
       " ('7836909K.pdf', '2-Oct-18', True, True),\n",
       " ('7891371L.pdf', '8-Jan-19', False, False),\n",
       " ('7096205N.pdf', '6-Aug-15', False, True)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(method_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(method_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = [\"source_files\", \"date_appeals\", \"cognition_related\", \"positive_decisions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"method_2.csv\", encoding = \"UTF-8\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You just harnessed the power of Python to accomplish the following tasks that are critical foundational skills to become an advanced data journalist:\n",
    "\n",
    "1. Using the power of automation for iterate through tedious, but important tasks.\n",
    "2. Tapping Python to iterate through calculations. In a few weeks, you'll be doing this on millions of rows.\n",
    "3. Allowing us to slow down how fast our code runs to avoid detection or being blocked when we start scraping websites!\n",
    "4. Processing data we have scraped into dataframes and/or csv files for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-for-week-3-SOLUTIONS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
